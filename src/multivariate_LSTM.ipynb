{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN+Z+1QaisHQENiJvLSfFlT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JS-Choi513/Predicting-the-Housing-Price-Index-in-Changwon-City-Using-the-LSTM-Model/blob/main/multivariate_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDoFIoF8ly9u"
      },
      "source": [
        "import os\r\n",
        "import datetime\r\n",
        "\r\n",
        "import IPython\r\n",
        "import IPython.display\r\n",
        "import matplotlib as mpl\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import tensorflow as tf\r\n",
        "# 데이터셋 업로드 \r\n",
        "from google.colab import files\r\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\r\n",
        "mpl.rcParams['axes.grid'] = False\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9guNBf-pDvf"
      },
      "source": [
        "\r\n",
        "\r\n",
        "#uploaded = files.upload() \r\n",
        "\r\n",
        "#for fn in uploaded.keys():\r\n",
        " # print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn]))) \r\n",
        "data = pd.read_csv('/content/integrated_data.csv')\r\n",
        "data['new_Date'] = pd.to_datetime(data['date'])\r\n",
        "print(data.head())\r\n",
        "print('\\n')\r\n",
        "print(data.info())\r\n",
        "print('\\n')\r\n",
        "print(type(data['new_Date'][0]))\r\n",
        "data.drop('date', axis = 1, inplace=True)\r\n",
        "data.set_index('new_Date', inplace=True)\r\n",
        "print(data.head())\r\n",
        "print('\\n')\r\n",
        "print(data.info())\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yTG27M6kgpK"
      },
      "source": [
        "data.head(5)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ_y4FQBcTcY"
      },
      "source": [
        "#data['house_loan'].plot()\r\n",
        "plt.plot(data['house_loan'])\r\n",
        "plt.show()\r\n",
        "plt.plot(data['consumer_price'])\r\n",
        "plt.show()\r\n",
        "plt.plot(data['building_space'])\r\n",
        "plt.show()\r\n",
        "plt.plot(data['interest_idx'])\r\n",
        "plt.show()\r\n",
        "plt.plot(data['housing_price'])\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZQzjctNuk-n"
      },
      "source": [
        "\r\n",
        "data.head(5)\r\n",
        "economic_stat = ['consumer_price','house_loan','building_space','interest_idx','housing_price']\r\n",
        "features = df[economic_stat]\r\n",
        "#features.index = df['date']\r\n",
        "print(features.head())\r\n",
        "features.plot(subplots=True)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joSbHn7HxQ9V"
      },
      "source": [
        "#훈련데이터 분할 \r\n",
        "#2008-01-01 ~ 2018-01-01\r\n",
        "# 각 데이터 원시값-평균/편차 => 데이터셋 표준화 \r\n",
        "TRAIN_SPLIT = 120\r\n",
        "dataset = features.values\r\n",
        "data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)\r\n",
        "data_std = dataset[:TRAIN_SPLIT].std(axis=0)\r\n",
        "dataset = (dataset-data_mean)/data_std\r\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoN7NEZm0xGS"
      },
      "source": [
        "#신경망 모델 훈련에 사용한 특정시간 윈도우 데이터 확보를 위한 함수 \r\n",
        "#history: 과거데이터 크기\r\n",
        "#target size 모델이 미래를 예측할 크기 \r\n",
        "# step값이 주어지면 step에 맞게 데이터를 샘플링 \r\n",
        "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step, single_step=False):\r\n",
        "    data = []\r\n",
        "    labels = []\r\n",
        "\r\n",
        "    start_index = start_index + history_size\r\n",
        "    if end_index is None:\r\n",
        "        end_index = len(dataset) - target_size\r\n",
        "\r\n",
        "    for i in range(start_index, end_index):\r\n",
        "        indices = range(i - history_size, i, step)\r\n",
        "        data.append(dataset[indices])\r\n",
        "\r\n",
        "        if single_step:\r\n",
        "            labels.append(target[i + target_size])\r\n",
        "        else:\r\n",
        "            labels.append(target[i:i + target_size])\r\n",
        "    return np.array(data), np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhc8mzmg3bb_"
      },
      "source": [
        "past_history = 6\r\n",
        "future_target = 3\r\n",
        "STEP = 6\r\n",
        "\r\n",
        "x_train_single, y_train_single = multivariate_data(dataset, dataset[:, 1], 0, TRAIN_SPLIT, past_history,\r\n",
        "                                                   future_target, STEP, single_step=True)\r\n",
        "x_val_single, y_val_single = multivariate_data(dataset, dataset[:, 1], TRAIN_SPLIT, None, past_history,\r\n",
        "                                               future_target, STEP, single_step=True)\r\n",
        "\r\n",
        "print('Single window of past history : {}'.format(x_train_single[0].shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q25eFfDG5pAO"
      },
      "source": [
        "BATCH_SIZE = 256\r\n",
        "BUFFER_SIZE = 10000\r\n",
        "EVALUATION_INTERVAL = 200\r\n",
        "EPOCHS = 10\r\n",
        "train_data_single = tf.data.Dataset.from_tensor_slices((x_train_single, y_train_single))\r\n",
        "train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\r\n",
        "\r\n",
        "val_data_single = tf.data.Dataset.from_tensor_slices((x_val_single, y_val_single))\r\n",
        "val_data_single = val_data_single.batch(BATCH_SIZE).repeat()\r\n",
        "\r\n",
        "single_step_model = tf.keras.models.Sequential()\r\n",
        "single_step_model.add(tf.keras.layers.LSTM(32, input_shape=x_train_single.shape[-2:]))\r\n",
        "single_step_model.add(tf.keras.layers.Dense(1))\r\n",
        "single_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\r\n",
        "\r\n",
        "for x, y in val_data_single.take(1):\r\n",
        "    print(single_step_model.predict(x).shape)\r\n",
        "\r\n",
        "single_step_history = single_step_model.fit(train_data_single, epochs=EPOCHS,\r\n",
        "                                            steps_per_epoch=EVALUATION_INTERVAL,\r\n",
        "                                            validation_data=val_data_single,\r\n",
        "                                            validation_steps=50)\r\n",
        "\r\n",
        "\r\n",
        "def plot_train_history(history, title):\r\n",
        "    loss = history.history['loss']\r\n",
        "    val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "    epochs = range(len(loss))\r\n",
        "\r\n",
        "    plt.figure()\r\n",
        "\r\n",
        "    plt.plot(epochs, loss, 'b', label='Training loss')\r\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\r\n",
        "    plt.title(title)\r\n",
        "    plt.legend()\r\n",
        "\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "plot_train_history(single_step_history,\r\n",
        "                   'Single Step Training and Validation Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bVCbn8v7Kb2"
      },
      "source": [
        "def create_time_steps(length):\r\n",
        "    return list(range(-length, 0))\r\n",
        "\r\n",
        "\r\n",
        "def show_plot(plot_data, delta, title):\r\n",
        "    labels = ['History', 'True Future', 'Model Prediction']\r\n",
        "    marker = ['.-', 'rx', 'go']\r\n",
        "    time_steps = create_time_steps(plot_data[0].shape[0])\r\n",
        "    if delta:\r\n",
        "        future = delta\r\n",
        "    else:\r\n",
        "        future = 0\r\n",
        "\r\n",
        "    plt.title(title)\r\n",
        "    for i, x in enumerate(plot_data):\r\n",
        "        if i:\r\n",
        "            plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\r\n",
        "        else:\r\n",
        "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\r\n",
        "    plt.legend()\r\n",
        "    plt.axis('auto')\r\n",
        "    plt.xlim([time_steps[0], (future+5)*2])\r\n",
        "    plt.xlabel('Time-Step')\r\n",
        "    return plt\r\n",
        "\r\n",
        "for x, y in val_data_single.take(3):\r\n",
        "    plot = show_plot([x[0][:, 1].numpy(), y[0].numpy(),\r\n",
        "                      single_step_model.predict(x)[0]], 5,\r\n",
        "                     'Single Step Prediction')\r\n",
        "    plot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}