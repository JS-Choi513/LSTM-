{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi_step_LSTM",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDoFIoF8ly9u"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from google.colab import files\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9guNBf-pDvf"
      },
      "source": [
        "uploaded = files.upload() \n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn]))) \n",
        "data = pd.read_csv('/content/integrated_data.csv')\n",
        "data['new_Date'] = pd.to_datetime(data['date'])\n",
        "print(data.head())\n",
        "print('\\n')\n",
        "print(data.info())\n",
        "print('\\n')\n",
        "#첫번째 컬럼을 날짜형식 컬럼으로 변경 \n",
        "print(type(data['new_Date'][0]))\n",
        "data.drop('date', axis = 1, inplace=True)\n",
        "data.set_index('new_Date', inplace=True)\n",
        "print(data.head())\n",
        "print('\\n')\n",
        "print(data.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yTG27M6kgpK"
      },
      "source": [
        "# 5열까지 출력 \n",
        "data.head(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ_y4FQBcTcY"
      },
      "source": [
        "#data['house_loan'].plot()\n",
        "plt.title(\"household_loan\")\n",
        "plt.plot(data['house_loan'])\n",
        "plt.show()\n",
        "plt.title(\"consuming_price_idx\")\n",
        "plt.plot(data['consumer_price'])\n",
        "plt.show()\n",
        "plt.title(\"building_permitted_area\")\n",
        "plt.plot(data['building_space'])\n",
        "plt.show()\n",
        "plt.title(\"Interest_rate\")\n",
        "plt.plot(data['interest_idx'])\n",
        "plt.show()\n",
        "plt.title(\"housing price_idx\")\n",
        "plt.plot(data['housing_price'])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZQzjctNuk-n"
      },
      "source": [
        "data.head()\n",
        "economic_stat = ['consumer_price','house_loan','building_space','interest_idx','housing_price']\n",
        "features = data[economic_stat]\n",
        "print(features.head(156))\n",
        "print(features.values)\n",
        "features.plot(subplots=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joSbHn7HxQ9V"
      },
      "source": [
        "#훈련데이터 분할 \n",
        "#2008-01-01 ~ 2018-01-01 120개월을훈련데이터로 분할 \n",
        "# 각 데이터 원시값-평균/표준편차 => 데이터셋 표준화 \n",
        "TRAIN_SPLIT =120\n",
        "tf.random.set_seed(13)\n",
        "dataset = features.values\n",
        "data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)#각 열에 대한120인덱스 까지의  평균값 \n",
        "data_std = dataset[:TRAIN_SPLIT].std(axis=0)# 각 열에 대한 표준편차차\n",
        "print(data_std)\n",
        "dataset = (dataset-data_mean)/data_std\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoN7NEZm0xGS"
      },
      "source": [
        "#신경망 모델 훈련에 사용한 특정시간 윈도우 데이터 확보를 위한 메소드 \n",
        "#history: 과거데이터 크기\n",
        "#target size 모델이 미래를 예측할 크기 \n",
        "# step값이 주어지면 step에 맞게 데이터를 샘플링 \n",
        "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step, single_step=False):\n",
        "    data = []          \n",
        "    labels = []\n",
        "    start_index = start_index + history_size\n",
        "    if end_index is None:\n",
        "        print(\"dataset len %d\",len(dataset))\n",
        "        end_index = len(dataset) - target_size\n",
        "    for i in range(start_index, end_index+1):\n",
        "        indices = range(i - history_size, i, step) \n",
        "        print(indices)\n",
        "        data.append(dataset[indices])#\n",
        "  \n",
        "        if single_step:\n",
        "          labels.append(target[i + target_size])\n",
        "          print(label)\n",
        "          print('타겟 데이터')\n",
        "          print(target[i + target_size])\n",
        "        else:\n",
        "          labels.append(target[i:i + target_size])\n",
        "                \n",
        "    return np.array(data), np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACAPbNiqse_B"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhc8mzmg3bb_"
      },
      "source": [
        "past_history = 24\n",
        "future_target = 6\n",
        "STEP = 1\n",
        "\"\"\"\n",
        "데이터 샘플링 \n",
        "현재 보유중인 데이터: 월단위 \n",
        "데이터 스플릿 120개월, 총 데이터 156 13년 20081.1 2020121\n",
        "샘플링 단위 1개월 \n",
        "과거 2년(24개월) 단위로 3개월 씩 샘플링 \n",
        "타겟 1개월 예측 \n",
        "range(0, 24, 1) \n",
        "range(1, 25, 1)\n",
        "range(2, 26, 1)\n",
        "range(3, 27, 3)\n",
        "range(4, 28, 3)\n",
        "range(5, 29, 3)\n",
        "range(6, 30, 3)\n",
        "range(7, 31, 3)\n",
        "range(8, 32, 3)\n",
        "학습 타겟 데이터: 훈련데이터가 매 샘플마다 저장될 때 레이블 데이터는 \n",
        "해당 샘플의 마지막 인덱스+1(24일 때 25, 바로 다음달 ) 한 값을 타겟데이터로 저장 \n",
        "\"\"\"\n",
        "\n",
        "x_train_multi, y_train_multi = multivariate_data(dataset, dataset[:, 4], 0, TRAIN_SPLIT, past_history, future_target, STEP)#0 ~ 30000\n",
        "print('-----------------------------------')\n",
        "\n",
        "# 예측해야할 데이터셋  11개 윈도우 120 ~ 154\n",
        "x_val_multi, y_val_multi = multivariate_data(dataset, dataset[:, 4], TRAIN_SPLIT, None, past_history, future_target, STEP)#30000 ~ end\n",
        "\n",
        "print('Single window of past history : {}'.format(x_train_multi[0].shape))\n",
        "print(y_train_multi)\n",
        "print('================================================================')\n",
        "print('\\n Target temperature to predict : {}'.format(y_val_multi[0].shape))\n",
        "print(x_val_multi)\n",
        "print('y')\n",
        "print(y_val_multi)\n",
        "# 처음부터 약2년까지의  3개월 단위 표준화 데이터셋 5개의 컬럼, 8개 행.\n",
        "\n",
        "# 훈련데이터 차원 130,8,5..?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q25eFfDG5pAO"
      },
      "source": [
        "BATCH_SIZE = 128##144 #128#256\n",
        "#Batch는 일괄 처리되는 작업의 양이다. 위에서 설명된 data_size를 한번에 처리하는 갯수를 의미하며, \n",
        "#batch크기에 의해 weight 변화가 일어나며 batch크기 단위로 data loading 함수도 구현이 가능하다. \n",
        "#주의할점은 data_size/batch_size일때 나머지가 없어야 한다.\n",
        "BUFFER_SIZE = 4096 #데이터 14000\n",
        "EVALUATION_INTERVAL = 18\n",
        "EPOCHS = 100\n",
        "# 입력된 텐서로부터 slices를 생성한다. \n",
        "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
        "count =0\n",
        "for element in train_data_multi:\n",
        "  print(\"훈련데이터 슬라이스\")\n",
        "  count = count+1\n",
        "  print(element)\n",
        "print(count)  \n",
        "  # 입력된 텐서로부터 slices를 생성한다. 무기한 반복\n",
        "train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "# 데이터 캐싱, 훈련데이터 셔플 \n",
        "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi)) #11,9,5 11,0\n",
        "#.astype(float)\n",
        "#.astype(float)\n",
        "for element in val_data_multi:\n",
        "  print(\"평가데이터 슬라이스\")\n",
        "  print(element)\n",
        "print(\"이;거뭕ㄷ데\")\n",
        "print(val_data_multi)\n",
        "val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "\n",
        "\n",
        "print(x_train_multi.shape) #96,25,5\n",
        "print(x_train_multi.shape[-2:])\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        "multi_step_model = tf.keras.models.Sequential()\n",
        "#입력데이터 형식: 소비자물가지수, 가계대출금, 금리, 건축허가면적, 주택가격지수  입력형식 [8,5]\n",
        "multi_step_model.add(tf.keras.layers.LSTM(32, return_sequences=True, input_shape=x_train_multi.shape[-2:])) #,dropout=0.5\n",
        "multi_step_model.add(tf.keras.layers.LSTM(16, activation='relu'))\n",
        "multi_step_model.add(tf.keras.layers.Dense(6))\n",
        "\n",
        "multi_step_model.compile(optimizer=tf.keras.optimizers.Adam(), loss = root_mean_squared_error)# 에러 절댓값 평균ingle_step_model.add(tf.keras.layers.Dense(1))\n",
        "    #Adam()RMSprop()\n",
        "#print(len(single_step_model.layers))#2\n",
        "#훈련시작 배치크기 50회 학습, \n",
        "for x, y in val_data_multi.take(3):\n",
        "  print(x.shape)\n",
        "  print('이게뭔데 그래서')\n",
        "  print(multi_step_model.predict(x).shape)\n",
        "        \n",
        "multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n",
        "                                            steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                                            validation_data=val_data_multi,\n",
        "                                            validation_steps=3)\n",
        "#steps_per_epoch [트레이닝데이터수/배치사이즈]\n",
        "#validation_steps validation data수/배치사이즈\n",
        "\n",
        "\n",
        "print(multi_step_history)\n",
        "def plot_train_history(history, title):\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(len(loss))\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_train_history(multi_step_history,\n",
        "                   'Single Step Training and Validation Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bVCbn8v7Kb2"
      },
      "source": [
        "def create_time_steps(length):\n",
        "    return list(range(-length, 0))\n",
        "\n",
        "\n",
        "def multi_step_plot(history, true_future, prediction):\n",
        "  plt.figure(figsize=(12,6))\n",
        "  num_in = create_time_steps(len(history))\n",
        "  num_out = len(true_future)\n",
        "  plt.plot(num_in, np.array(history[:,4]), label='History')\n",
        "  plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n",
        "           label='True Future')\n",
        "  if prediction.any():\n",
        "    plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',label='Predictied Future')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "for x,y in train_data_multi.take(1):\n",
        "  multi_step_plot(x[0],y[0], np.array([0]))      \n",
        "for x,y in val_data_multi.take(3):\n",
        "  multi_step_plot(x[0],y[0], multi_step_model.predict(x)[0])\n",
        "  print(x.shape)\n",
        "  print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GtoPifEG8c_"
      },
      "source": [
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.title(\"Pridicting All time Housing price\")\n",
        "plt.plot(data['housing_price'])\n",
        "pridict = []\n",
        "for x,y in train_data_multi.take(1):\n",
        "  print(multi_step_model.predict(x).shape)\n",
        "  print(multi_step_model.predict(x))\n",
        "  #for window in range(96):\n",
        "  #plt.show()\n",
        "  print(x.shape)\n",
        "print(\"---------원본데이터-------------------------------\") \n",
        "print(data.shape)\n",
        "print(data[:,4])\n",
        "\n",
        "#  if prediction.any():\n",
        "\n",
        "#    plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',label='Predictied Future')\n",
        "#plt.legend(loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}